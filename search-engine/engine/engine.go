package engine

import (
	"Search-Engine/search-engine/model"
	"Search-Engine/search-engine/sort"
	"Search-Engine/search-engine/storage"
	"Search-Engine/search-engine/util"
	tokenizer2 "Search-Engine/search-engine/words/tokenizer"
	"fmt"
	"sync"
)

type Engine struct {
	IndexPath            string                    // ç´¢å¼•æ•°æ®å­˜æ”¾çš„è·¯å¾„
	Tokenizer            *tokenizer2.Tokenizer     // åˆ†è¯å™¨
	InvertedIndexStorage []*storage.LeveldbStorage // å€’æ’ç´¢å¼• term ==> id list
	PositiveIndexStorage []*storage.LeveldbStorage // æ­£æ’ç´¢å¼• id ==> terms
	RepositoryStorage    []*storage.LeveldbStorage // id ==> terms + attrs
	ShardNum             int                       // shardæ•°ç›®ï¼ˆé»˜è®¤10ï¼‰
	BufferNum            int                       // æ¯ä¸ªshardå­˜æ”¾çš„kvå¯¹çš„æ•°é‡ï¼ˆé»˜è®¤1000ï¼‰
	AddIndexDocChan      []chan *model.IndexDoc    // ç”¨äºæ¥æ”¶éœ€è¦æ„å»ºçš„ IndexDoc çš„ channel

	InvertIndexName       string // ä¸‰ä¸ªç´¢å¼•æ–‡ä»¶çš„å‰ç¼€åç§°
	PositiveIndexName     string
	RepositoryStorageName string
	DocumentCnt           int
	TimeOut               int64 // è¶…æ—¶æ—¶é—´

	mutex sync.Mutex
	wg    sync.WaitGroup // ç”¨äºåŒæ­¥ åˆå§‹åŒ– å’Œ æ‰§è¡Œç´¢å¼•æ“ä½œçš„ goroutine
}

func (engine *Engine) Init() {
	engine.wg.Add(1)
	defer engine.wg.Done()

	if engine.ShardNum == 0 {
		engine.ShardNum = 10
	}
	if engine.BufferNum == 0 {
		engine.BufferNum = 1000
	}
	engine.AddIndexDocChan = make([]chan *model.IndexDoc, engine.ShardNum)
	for i := 0; i < engine.ShardNum; i++ {
		engine.AddIndexDocChan[i] = make(chan *model.IndexDoc, engine.BufferNum)
		go engine.AddIndexDocLoop(engine.AddIndexDocChan[i])
		// åˆå§‹åŒ–ä¸‰ä¸ª Leveldb çš„è®¿é—®
		invertIndexFileName := fmt.Sprintf("%s_%d", engine.InvertIndexName, i)
		positiveIndexFileName := fmt.Sprintf("%s_%d", engine.PositiveIndexName, i)
		repositoryStorageName := fmt.Sprintf("%s_%d", engine.RepositoryStorageName, i)
		// å€’æ’ç´¢å¼•
		s, err := storage.NewStorage(engine.IndexPath+"/"+invertIndexFileName, engine.TimeOut)
		if err != nil {
			panic(err)
		}
		engine.InvertedIndexStorage = append(engine.InvertedIndexStorage, s)
		// æ­£æ’ç´¢å¼•
		sP, errP := storage.NewStorage(engine.IndexPath+"/"+positiveIndexFileName, engine.TimeOut)
		if errP != nil {
			panic(err)
		}
		engine.PositiveIndexStorage = append(engine.PositiveIndexStorage, sP)
		// æ–‡æ¡£å­˜å‚¨
		sS, errS := storage.NewStorage(engine.IndexPath+"/"+repositoryStorageName, engine.TimeOut)
		if errS != nil {
			panic(errS)
		}
		engine.RepositoryStorage = append(engine.RepositoryStorage, sS)
		fmt.Println("End of new engine function.")
	}
}

func (engine *Engine) AddIndexDocLoop(worker chan *model.IndexDoc) {
	for {
		indexDoc := <-worker // è¯•å›¾ä»channelä¸­è¯»å–å¾…æ·»åŠ çš„Docï¼Œæ²¡æœ‰çš„è¯å°±é˜»å¡åœ¨è¿™é‡Œ
		fmt.Println("æˆåŠŸæ·»åŠ IndexDocåˆ°Channelä¸­, docId:", indexDoc.Key, "text", indexDoc.Text, "attrs", indexDoc.Attrs)
		engine.AddIndexDoc2Engine(indexDoc)
	}
}

func (e *Engine) AddIndexDoc2Chan(indexDoc *model.IndexDoc) {
	// éœ€è¦ç­‰å¾…åˆå§‹åŒ–å®Œæˆæ‰èƒ½æ·»åŠ ç´¢å¼•
	docId := indexDoc.Key
	e.DocumentCnt++
	e.AddIndexDocChan[e.GetShardNumByDocId(docId)] <- indexDoc
}

func (e *Engine) AddIndexDoc2Engine(indexDoc *model.IndexDoc) {
	// ç­‰å¾…åˆå§‹åŒ–å®Œæˆåè¿›è¡Œæ•°æ®æ·»åŠ 
	e.wg.Wait()

	docId := indexDoc.Key
	terms := e.Tokenizer.Cut(indexDoc.Text)
	/*
		  å€’æ’ç´¢å¼•ï¼š
				å¦‚æœè¯´ docId ä¹‹å‰æ˜¯ä¸å­˜åœ¨çš„ï¼Œé‚£ä¹ˆå°±æ˜¯çº¯å¢åŠ ã€‚
				å¦‚æœ doc ä¹‹å‰æ˜¯å­˜åœ¨è¿‡çš„ï¼Œé‚£ä¹ˆå°±å¯èƒ½æ¶‰åŠåˆ°æ›´æ”¹
				old:
					docId:123
					terms: è‹¹æœã€é¦™è•‰ã€æ¢¨å­ã€ç«é¾™æœ
				new:
					docId:123
					terms: è‹¹æœã€è‘¡è„ã€æ —å­ã€ç«é¾™æœ

				   é’ˆå¯¹äº æ–°å¢çš„ [è‘¡è„ã€æ —å­] å¯¹åº”çš„å€’æ’é“¾ä¸­ï¼Œå°±åº”è¯¥åŠ ä¸Š docID
			       é’ˆå¯¹äº ç§»é™¤çš„ [é¦™è•‰ã€æ¢¨å­] å¯¹åº”çš„å€’æ’é“¾ä¸­ï¼Œå°±åº”è¯¥å»æ‰ docID
		  æ­£æ’ç´¢å¼•ï¼š
				é’ˆå¯¹äºæ­£æ’ç´¢å¼• (docId ===> [terms], docId ===> [terms + document]) æ¥è¯´ï¼Œ
				å…¶å®ç›´æ¥åœ¨ Leveldb ä¸­ Set å°±å¯ä»¥äº†, å› ä¸ºå³ä½¿docIdæ›¾ç»ä½œä¸ºkeyå­˜åœ¨äºdbä¸­ï¼Œleveldb
				ä¹Ÿä¼šå°†valueç»™æ›¿æ¢æ‰ã€‚
	*/
	terms2bRemoved, terms2bInserted := e.PrepareForHandle(terms, docId) // å†…ç½®äº†å¯¹äºDBçš„handleï¼Œ éœ€è¦è¿›è¡ŒåŠ é”ğŸ”’
	fmt.Printf("The len of remove:%d, the len of insert:%d", len(terms2bRemoved), len(terms2bInserted))
	// å€’æ’ç´¢å¼•ï¼šåˆ é™¤ç´¢å¼•
	for _, value := range terms2bRemoved {
		e.RemoveDocIdInInvertIndex(value, docId)
	}
	// å€’æ’ç´¢å¼•ï¼šæ–°å¢ç´¢å¼•
	for _, value := range terms2bInserted {
		e.AddDocIdInInvertIndex(value, docId)
	}

	// æ›´æ–°æ­£æ’ç´¢å¼•
	e.AddIndexDoc2PositiveIndex(indexDoc, terms)
}

func (e *Engine) AddIndexDoc2PositiveIndex(indexDoc *model.IndexDoc, terms []string) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	index := e.GetShardNumByDocId(indexDoc.Key)
	positiveIndex := e.PositiveIndexStorage[index]
	reposIndex := e.RepositoryStorage[index]

	repos := &model.RepositoryIndexDoc{
		IndexDoc: indexDoc,
		Terms:    terms,
	}

	// id ===> [terms]
	positiveIndex.Set(util.Uint32ToBytes(indexDoc.Key), util.Encoder(terms))
	// id ===> [terms + attrs]
	reposIndex.Set(util.Uint32ToBytes(indexDoc.Key), util.Encoder(repos))
}

func (e *Engine) PrepareForHandle(terms []string, docId uint32) ([]string, []string) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	docIndex := e.GetShardNumByDocId(docId)
	positiveIndex := e.PositiveIndexStorage[docIndex] // ä»é‡Œé¢å–åˆ°çš„listæ˜¯docId ===> term list
	buf, exist := positiveIndex.Get(util.Uint32ToBytes(docId))
	var terms2bRemoved []string
	var terms2bInserted []string
	if !exist { // docId æœ¬èº«å°±æ˜¯ä¸å­˜åœ¨çš„ï¼Œé‚£ä¹ˆç›´æ¥æ·»åŠ ç´¢å¼•æ•°æ®
		terms2bInserted = terms
	} else { // docId æœ¬èº«æ˜¯å­˜åœ¨çš„ï¼Œé‚£ä¹ˆæœ¬æ¬¡ä¼ é€’è¿‡æ¥çš„æ•°æ®å¯èƒ½æ¶‰åŠåˆ°å€’æ’ç´¢å¼•çš„æ›´æ–°(æ–°å»ºã€åˆ é™¤)
		var oldTermList []string
		util.Decoder(buf, &oldTermList)
		// éœ€è¦è¢«åˆ é™¤æ‰çš„ terms
		for _, oldTerm := range oldTermList {
			_, exist := util.ExistInArrayString(terms, oldTerm)
			if !exist {
				terms2bRemoved = append(terms2bRemoved, oldTerm)
			}
		}
		// éœ€è¦æ–°å¢çš„ terms
		for _, newTerm := range terms {
			_, exist := util.ExistInArrayString(oldTermList, newTerm)
			if !exist {
				terms2bInserted = append(terms2bInserted, newTerm)
			}
		}
	}
	return terms2bRemoved, terms2bInserted
}

// ç»™åˆ° term å¯¹åº”çš„å€’æ’é“¾ä¸­æ·»åŠ ä¸€ä¸ª docId
func (e *Engine) AddDocIdInInvertIndex(term string, docId uint32) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	fmt.Println("æ‰§è¡Œå€’æ’ç´¢å¼•ç»“æ„çš„å¢æ·», term:", term, ", docId:", docId)
	var docIdList = make([]uint32, 0)
	invertIndex := e.InvertedIndexStorage[e.GetShardNumByTerm(term)]
	buf, exist := invertIndex.Get([]byte(term))
	if !exist {
		docIdList = append(docIdList, docId)
		fmt.Println("AddInvertIndex function, æ²¡æœ‰%sæ„å»ºçš„å€’æ’ç´¢å¼•", term)
	} else {
		util.Decoder(buf, &docIdList)
		if _, exist := util.ExistInArrayUint32(docIdList, docId); !exist {
			docIdList = append(docIdList, docId)
		}
		fmt.Println("AddInvertIndex function, å°†%dæ·»åŠ åˆ°%så¯¹åº”çš„å€’æ’æ‹‰é“¾ä¸­", docId, term)
	}
	// å°†æ›´æ–°åçš„ docIdList è®¾ç½®åˆ° db ä¸­
	invertIndex.Set([]byte(term), util.Encoder(docIdList))
}

func (e *Engine) RemoveDocIdInInvertIndex(term string, docId uint32) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	var docIdList = make([]uint32, 0)
	invertIndex := e.InvertedIndexStorage[e.GetShardNumByTerm(term)]
	buf, exist := invertIndex.Get([]byte(term))
	if exist {
		util.Decoder(buf, &docIdList)
		// å°† id ä» list ä¸­åˆ é™¤
		docIdList = util.RemoveUint32ValueInArray(docIdList, docId)
		if len(docIdList) == 0 {
			// è¿™ä¸ªå€’æ’ç´¢å¼•å·²ç»ç©ºäº†ï¼Œç›´æ¥åˆ æ‰
			if err := invertIndex.Delete([]byte(term)); err != nil {
				panic(err)
			}
		} else {
			invertIndex.Set([]byte(term), util.Encoder(docIdList))
		}
	}
}

func (e *Engine) Search(request *model.SearchRequest) (*model.SearchResponse, error) {
	searchContext := &sort.SearchContext{} // æœ¬æ¬¡æœç´¢çš„ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬å¾…é€‰æ•°æ®é›†ç­‰ï¼‰
	// 1. é¦–å…ˆå¯¹äº query è¿›è¡Œåˆ†è¯å¤„ç†
	terms := e.Tokenizer.Cut(request.Query)
	termCnt := len(terms)
	// 2. æŸ¥è¯¢å€’æ’ç´¢å¼•ï¼Œè·å– terms å¯¹åº”çš„ docIdList ä½œä¸ºå€™é€‰ç»“æœé›†ï¼Œåç»­æ’åºå•¥çš„ç”¨
	wg := &sync.WaitGroup{}
	for i := 0; i < termCnt; i++ {
		go e.AddDocIdList2ContextByTerm(terms[i], searchContext, wg)
		wg.Done()
	}
	wg.Wait() // ç­‰å¾…å¤šçº¿ç¨‹å®Œæˆå¯¹äºä¸åŒåˆ†ç‰‡çš„ å€™é€‰é›† çš„æ·»åŠ 

	// 3. Preprocessing é¢„å¤„ç†æ•°æ®, è·å¾—å¾…é€‰é›†docå‘½ä¸­çš„termæ•°é‡
	searchContext.PreProcess()
	// 4. AssignScore èµ‹åˆ†æ•°
	searchContext.AssignScores()
}

func (e *Engine) AddDocIdList2ContextByTerm(term string, context *sort.SearchContext, wg *sync.WaitGroup) {
	defer wg.Done()
	index := e.GetShardNumByTerm(term)
	invertIndex := e.InvertedIndexStorage[index]
	var docIdList []uint32
	buf, exist := invertIndex.Get([]byte(term))
	if exist {
		util.Decoder(buf, &docIdList)
		context.AddCandidate(&docIdList)
	}
}

func (e *Engine) GetShardNumByDocId(docId uint32) int {
	return int(docId % uint32(e.ShardNum))
}

func (e *Engine) GetShardNumByTerm(term string) int {
	// murmur hash ==> hash code
	hashCode := util.String2Int(term)
	return int(hashCode % uint32(e.ShardNum))
}
